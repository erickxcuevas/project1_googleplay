# -*- coding: utf-8 -*-
"""Business_case_googleplay.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PFH1VtscUXYbppuTCXadd5PNii3JAFWo

# **Code - Business Case Google Play**
### *By: Erick Cuevas*
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Read the datasets
df1 = pd.read_csv('/content/googleplaystore_user_reviews.csv') #provides details and numeric ratings of google play apps
df2 = pd.read_csv('/content/googleplaystore.csv') #provides reviews of apps (doesn't include apps starting with the letter H onwards)

"""
### DF1 (user reviews file) processing"""

#Obtain a first glance / initial info of the dataset
df1.info()

#Search por null values
print(df1.isnull().sum())
print(df1.shape)

#Drop null values using column "sentiment" as reference
df1.dropna(subset=['Sentiment'],inplace=True)

#Make sure there are no null values
print(df1.isnull().sum())
print(df1.shape)

#Count the number of registers/reviews with a "positive" sentiment of each app
count_positive = df1[df1['Sentiment'] == 'Positive'].groupby('App')['Sentiment'].count()
print(count_positive)

#Get the apps with greater count of "positive" reviews and create dataset
df1_positive_count = count_positive.reset_index()
df1_positive_count.sort_values(by="Sentiment",ascending=False)

#Plot the apps with the best rating according to positive count
top_positive = df1_positive_count.nlargest(5, 'Sentiment')#Get the top

plt.bar(top_positive['App'], top_positive['Sentiment'], color="green")#Create a bar chart

for index, value in enumerate(top_positive['Sentiment']):
    plt.text(index, value + 1, str(value), ha='center', va='bottom', fontsize=10,color='black')

#Add labels and title
plt.xlabel('App')
plt.ylabel('Positive count')
plt.title('Top rated apps (Sentiment)')
plt.xticks(rotation=90)
plt.show()

#Count the number of registers/reviews with a "negative" sentiment of each app
count_negative = df1[df1['Sentiment'] == 'Negative'].groupby('App')['Sentiment'].count()
print(count_negative)

#Sort the apps and obtain the ones with greater count of "negative" reviews and create dataset
df1_negative_count = count_negative.reset_index()
df1_negative_count.sort_values(by="Sentiment",ascending=False)

#Plot the apps with the worst rating according to negative count
top_neg = df1_negative_count.nlargest(5, 'Sentiment')#Get the top

plt.bar(top_neg['App'], top_neg['Sentiment'], color="red")#Create a bar chart

for index, value in enumerate(top_neg['Sentiment']):
    plt.text(index, value + 1, str(value), ha='center', va='bottom', fontsize=10,color='black')

#Add labels and title
plt.xlabel('App')
plt.ylabel('Positive count')
plt.title('Top rated apps (Sentiment)')
plt.xticks(rotation=90)
plt.show()

"""### DF2 (apps info file) processing pt. 1"""

#Obtain a first glance / initial info of the dataset
df2.info()

#Search for null values
print(df2.isnull().sum())
print(df2.shape)

#Look registers with missing values in column "Rating"
missing_rating_rows = df2[df2['Rating'].isnull()]
print(missing_rating_rows)

#Replace the missing values from variable "Rating" with '0'
df2['Rating'] = df2['Rating'].fillna(0)
df2['Rating'].isnull().sum()

#Ensure null values were dropped
print(df2.isnull().sum())
print(df2.shape)

#Search for duplicates
df2.duplicated().sum()

#Get rid of duplicates
df2.drop_duplicates(inplace=True)

#Invalid literal for int() with base 10: '3.0M'
df2['Reviews'] = df2['Reviews'].replace('3.0M', 3000000)

#Remove row due to data mismatch
df2 = df2[df2['Rating'] != 19]

#Convert data types of key columns
df2['Reviews'] = df2['Reviews'].astype(int)
df2['Rating'] = df2['Rating'].astype(float)


#Remove special characters and conver data types from other columns
remove = ['+',',','$']
columns = ['Installs', 'Price']
for col in columns:
    for char in remove:
        df2[col] = df2[col].apply(lambda x: x.replace(char, ''))

df2['Installs'] = df2['Installs'].astype(int)
df2['Price'] = df2['Price'].astype(float)

print(df2.info())

#Obtain apps/registers with highest number of reviews
df2.sort_values(by='Reviews',ascending=False).head(20)

#Look for any duplicate values for the same App
df2['App'].value_counts()

#Drop duplicated registers of apps and keep the ones with the highest number of reviews (the latest one)
df2_no_dups = df2.sort_values(by='Reviews', ascending=False).drop_duplicates(subset='App', keep='first')

#Obtain info of the dataset after dropping duplicates
df2_no_dups.info()

"""### DF1 + DF2 MERGE"""

#Join both dataframes using merge and using "App" as the key column
left_merged = pd.merge(df1, df2_no_dups, how="left", on=["App"])
left_merged.shape

#It's worth mentioning that the best option would be "left join" considering that the first
#dataframe is the one of the user reviews, which doesn't include all apps. This mean that
#both dataframes will be joined by "App" column. Basically the info from the DF2 (app info dataset)
#will be added to the DF1 only if both share the same "App" name/value.

left_merged.head(10)

"""### DF2 (apps info file) processing pt. 2"""

#Obtain apps/registers with highest number of reviews (avoiding duplicates)
df2_no_dups.sort_values(by='Reviews',ascending=False).head(5)

#Create bar chart for the apps with more reviews
top_values = df2_no_dups.nlargest(10, 'Reviews') #Get the top 10

plt.bar(top_values['App'], top_values['Reviews'])#Create a bar chart

#Annotate each bar with its value
for index, value in enumerate(top_values['Reviews']):
    plt.text(index, value + 1, str(value), ha='center', va='bottom', fontsize=6,color='#4958B5')


#Add labels and title
plt.xlabel('App')
plt.ylabel('Reviews')
plt.title('Which app has more reviews?')
plt.xticks(rotation=90)
plt.show()

#Obtain apps/registers with the best rating
df2_no_dups.sort_values(by='Rating',ascending=False).head(10)

#Plot the apps with the best rating
top_rating = df2_no_dups.nlargest(30, 'Rating')#Get the top

plt.bar(top_rating['App'], top_rating['Rating'], color="green")#Create a bar chart

#Add labels and title
plt.xlabel('App')
plt.ylabel('Rating')
plt.title('Top rated apps')
plt.xticks(rotation=90)
plt.show()

#Obtain apps/registers with the worst rating
df2_no_dups.sort_values(by='Rating',ascending=True).head(20)

#obtain the number of registers with a rating of 0 (worst rating)

count_0 = df2_no_dups[df2_no_dups['Rating'] == 0].shape[0]
print(count_0)

#obtain the number of registers with a rating of 5 (best rating)
count_5 = df2_no_dups[df2_no_dups['Rating'] == 5.0].shape[0]
print(count_5)

#Create datasets according to diff number of reviews
filtered_df_10M = df2_no_dups[df2_no_dups['Reviews'] > 10000000]
filtered_df_1M = df2_no_dups[df2_no_dups['Reviews'] > 1000000]
filtered_df_500k = df2_no_dups[df2_no_dups['Reviews'] > 500000]
filtered_df_100k = df2_no_dups[df2_no_dups['Reviews'] > 100000]

#Create a loop to obtain a bar chart with the top 5 ratings for filtered datasets with diff number of reviews

filtered_datasets = [df2_no_dups, filtered_df_10M, filtered_df_1M, filtered_df_500k, filtered_df_100k]
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']

for j, color in zip(filtered_datasets,colors):
  top_5 = j.nlargest(5, 'Rating')
  #top_5 = j.nlargest(5, 'Rating',keep='all')

  plt.barh(top_5['App'], top_5['Rating'], color=color)

  for i, value in enumerate(top_5['Rating']):
    plt.text(value, i, str(value), color= 'black')

  plt.xlabel('Rating')
  plt.ylabel('Apps')
  plt.title('Top 5 Rated Apps')
  plt.show()

#Create a loop to obtain a bar chart with the worst rated apps for filtered datasets with diff number of reviews

filtered_datasets = [df2_no_dups, filtered_df_10M, filtered_df_1M, filtered_df_500k, filtered_df_100k]
colors = ['black', 'blue', 'aqua', 'lime', 'navy']

for j, color in zip(filtered_datasets,colors):
  worst_3 = j.nsmallest(3, 'Rating')

  plt.barh(worst_3['App'], worst_3['Rating'], color=color)

  for i, value in enumerate(worst_3['Rating']):
    plt.text(value, i, str(value), color= 'black')

  plt.xlabel('Rating')
  plt.ylabel('Apps')
  plt.title('Least liked Apps')
  plt.show()

#Group the register by category and obtain the mean rating of each one
df2_cat_rating = df2_no_dups.groupby('Category')['Rating'].mean()
df2_cat_rating.sort_values(ascending=False)

#Group the registers by category and obtain the size of each one
df2_cat_counts = df2_no_dups.groupby('Category').size()
df2_cat_counts.sort_values(ascending=False)

#Obtain the percentage of each category based on the size
#Create a dataset with that info

df2_cat_perc = df2_cat_counts.reset_index()
total_cat = df2_cat_perc[0].sum()
df2_cat_perc['Percentage'] = (df2_cat_perc[0]/total_cat)*100
df2_cat_perc.sort_values(by=0,ascending=False)

#Plot the top 5 categories in a pie chart

sorted_data = sorted(zip(df2_cat_perc['Category'], df2_cat_perc[0]), key=lambda x: x[1], reverse=True)

#Separate the top 5 categories and sum of sizes for the rest
top_labels = [item[0] for item in sorted_data[:5]]
top_sizes = [item[1] for item in sorted_data[:5]]
other_size = sum(item[1] for item in sorted_data[5:])

#Add the others category
top_labels.append("Others")
top_sizes.append(other_size)

#Create the pie chart
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#bcbd22']
plt.pie(top_sizes, labels=top_labels, autopct='%1.1f%%',labeldistance=1.15, wedgeprops = { 'linewidth' : 3, 'edgecolor' : 'white' },colors=colors)
plt.title('Top 5 App Categories')
plt.show()